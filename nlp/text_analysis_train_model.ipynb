{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk.data\n",
    "#nltk.download()\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name, nrows=None):\n",
    "    datasets = {\n",
    "        'unlabeled_train': 'unlabeledTrainData.tsv',\n",
    "        'labeled_train': 'labeledTrainData.tsv',\n",
    "        'test': 'testData.tsv'\n",
    "    }\n",
    "    if name not in datasets:\n",
    "        raise ValueError(name)\n",
    "    data_file = os.path.join('.', 'data', datasets[name])\n",
    "    df = pd.read_csv(data_file, sep='\\t', escapechar='\\\\', nrows=nrows)\n",
    "    print('Number of reviews: {}'.format(len(df)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9999_0</td>\n",
       "      <td>Watching Time Chasers, it obvious that it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45057_0</td>\n",
       "      <td>I saw this film about 20 years ago and remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15561_0</td>\n",
       "      <td>Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7161_0</td>\n",
       "      <td>I went to see this film with a great deal of e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43971_0</td>\n",
       "      <td>Yes, I agree with everyone on this site this m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             review\n",
       "0   9999_0  Watching Time Chasers, it obvious that it was ...\n",
       "1  45057_0  I saw this film about 20 years ago and remembe...\n",
       "2  15561_0  Minor Spoilers<br /><br />In New York, Joan Ba...\n",
       "3   7161_0  I went to see this film with a great deal of e...\n",
       "4  43971_0  Yes, I agree with everyone on this site this m..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_dataset('unlabeled_train')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eng_stopwords = set(stopwords.words('english'))\n",
    "eng_stopwords = {}.fromkeys([ line.rstrip() for line in open('.\\stopwords.txt')])\n",
    "\n",
    "def clean_text(text, remove_stopwords=False):\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    words = text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        words = [w for w in words if w not in eng_stopwords]\n",
    "    return words\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def print_call_counts(f):\n",
    "    n = 0\n",
    "    def wrapped(*args, **kwargs):\n",
    "        nonlocal n\n",
    "        n += 1\n",
    "        if n % 1000 == 1:\n",
    "            print('method {} called {} times'.format(f.__name__, n))\n",
    "        return f(*args, **kwargs)\n",
    "    return wrapped\n",
    "\n",
    "@print_call_counts\n",
    "def split_sentences(review):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = [clean_text(s) for s in raw_sentences if s]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method split_sentences called 1 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:424: MarkupResemblesLocatorWarning: \"http://www.archive.org/details/LovefromaStranger\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \"..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method split_sentences called 1001 times\n",
      "method split_sentences called 2001 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \". .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:424: MarkupResemblesLocatorWarning: \"http://www.loosechangeguide.com/LooseChangeGuide.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method split_sentences called 3001 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \". . .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \"....\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method split_sentences called 4001 times\n",
      "method split_sentences called 5001 times\n",
      "method split_sentences called 6001 times\n",
      "method split_sentences called 7001 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \"... ...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method split_sentences called 8001 times\n",
      "method split_sentences called 9001 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method split_sentences called 10001 times\n",
      "method split_sentences called 11001 times\n",
      "method split_sentences called 12001 times\n",
      "method split_sentences called 13001 times\n",
      "method split_sentences called 14001 times\n",
      "method split_sentences called 15001 times\n",
      "method split_sentences called 16001 times\n",
      "method split_sentences called 17001 times\n",
      "method split_sentences called 18001 times\n",
      "method split_sentences called 19001 times\n",
      "method split_sentences called 20001 times\n",
      "method split_sentences called 21001 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \".............................................................. ............................................................. .............................................................. .............................................................\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:424: MarkupResemblesLocatorWarning: \"http://www.msnbc.msn.com/id/4972055/site/newsweek/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method split_sentences called 22001 times\n",
      "method split_sentences called 23001 times\n",
      "method split_sentences called 24001 times\n",
      "method split_sentences called 25001 times\n",
      "method split_sentences called 26001 times\n",
      "method split_sentences called 27001 times\n",
      "method split_sentences called 28001 times\n",
      "method split_sentences called 29001 times\n",
      "method split_sentences called 30001 times\n",
      "method split_sentences called 31001 times\n",
      "method split_sentences called 32001 times\n",
      "method split_sentences called 33001 times\n",
      "method split_sentences called 34001 times\n",
      "method split_sentences called 35001 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:424: MarkupResemblesLocatorWarning: \"http://www.youtube.com/watch?v=a0KSqelmgN8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method split_sentences called 36001 times\n",
      "method split_sentences called 37001 times\n",
      "method split_sentences called 38001 times\n",
      "method split_sentences called 39001 times\n",
      "method split_sentences called 40001 times\n",
      "method split_sentences called 41001 times\n",
      "method split_sentences called 42001 times\n",
      "method split_sentences called 43001 times\n",
      "method split_sentences called 44001 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \".. .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method split_sentences called 45001 times\n",
      "method split_sentences called 46001 times\n",
      "method split_sentences called 47001 times\n",
      "method split_sentences called 48001 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\python\\lib\\site-packages\\bs4\\__init__.py:424: MarkupResemblesLocatorWarning: \"http://jake-weird.blogspot.com/2007/08/beneath.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method split_sentences called 49001 times\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "sentences = sum(df.review.apply(split_sentences), [])\n",
    "print('complete')\n",
    "#print('{} reviews -> {} sentences'.format(len(df), len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定词向量训练的参数\n",
    "num_features = 300    # Word vector dimensionality\n",
    "min_word_count = 40   # Minimum word count\n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "model_name = '{}features_{}minwords_{}context.model'.format(num_features, min_word_count, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 22:39:52,850 : INFO : collecting all words and their counts\n",
      "2022-07-27 22:39:52,852 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-07-27 22:39:52,895 : INFO : PROGRESS: at sentence #10000, processed 225422 words, keeping 17251 word types\n",
      "2022-07-27 22:39:52,939 : INFO : PROGRESS: at sentence #20000, processed 444646 words, keeping 24596 word types\n",
      "2022-07-27 22:39:52,982 : INFO : PROGRESS: at sentence #30000, processed 667960 words, keeping 29826 word types\n",
      "2022-07-27 22:39:53,031 : INFO : PROGRESS: at sentence #40000, processed 889338 words, keeping 33973 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 22:39:53,074 : INFO : PROGRESS: at sentence #50000, processed 1106734 words, keeping 37530 word types\n",
      "2022-07-27 22:39:53,125 : INFO : PROGRESS: at sentence #60000, processed 1330329 words, keeping 40768 word types\n",
      "2022-07-27 22:39:53,176 : INFO : PROGRESS: at sentence #70000, processed 1554297 words, keeping 43655 word types\n",
      "2022-07-27 22:39:53,230 : INFO : PROGRESS: at sentence #80000, processed 1776473 words, keeping 46194 word types\n",
      "2022-07-27 22:39:53,281 : INFO : PROGRESS: at sentence #90000, processed 1991507 words, keeping 48368 word types\n",
      "2022-07-27 22:39:53,336 : INFO : PROGRESS: at sentence #100000, processed 2215574 words, keeping 50596 word types\n",
      "2022-07-27 22:39:53,396 : INFO : PROGRESS: at sentence #110000, processed 2439393 words, keeping 52797 word types\n",
      "2022-07-27 22:39:53,445 : INFO : PROGRESS: at sentence #120000, processed 2664318 words, keeping 54945 word types\n",
      "2022-07-27 22:39:53,490 : INFO : PROGRESS: at sentence #130000, processed 2884350 words, keeping 56646 word types\n",
      "2022-07-27 22:39:53,541 : INFO : PROGRESS: at sentence #140000, processed 3104645 words, keeping 58402 word types\n",
      "2022-07-27 22:39:53,598 : INFO : PROGRESS: at sentence #150000, processed 3321123 words, keeping 60052 word types\n",
      "2022-07-27 22:39:53,654 : INFO : PROGRESS: at sentence #160000, processed 3542795 words, keeping 61755 word types\n",
      "2022-07-27 22:39:53,711 : INFO : PROGRESS: at sentence #170000, processed 3765675 words, keeping 63345 word types\n",
      "2022-07-27 22:39:53,766 : INFO : PROGRESS: at sentence #180000, processed 3986382 words, keeping 64893 word types\n",
      "2022-07-27 22:39:53,822 : INFO : PROGRESS: at sentence #190000, processed 4210941 words, keeping 66442 word types\n",
      "2022-07-27 22:39:53,873 : INFO : PROGRESS: at sentence #200000, processed 4437282 words, keeping 67966 word types\n",
      "2022-07-27 22:39:53,922 : INFO : PROGRESS: at sentence #210000, processed 4660746 words, keeping 69296 word types\n",
      "2022-07-27 22:39:53,976 : INFO : PROGRESS: at sentence #220000, processed 4878753 words, keeping 70623 word types\n",
      "2022-07-27 22:39:54,019 : INFO : PROGRESS: at sentence #230000, processed 5102002 words, keeping 71956 word types\n",
      "2022-07-27 22:39:54,066 : INFO : PROGRESS: at sentence #240000, processed 5319929 words, keeping 73284 word types\n",
      "2022-07-27 22:39:54,125 : INFO : PROGRESS: at sentence #250000, processed 5540569 words, keeping 74515 word types\n",
      "2022-07-27 22:39:54,191 : INFO : PROGRESS: at sentence #260000, processed 5761244 words, keeping 75741 word types\n",
      "2022-07-27 22:39:54,238 : INFO : PROGRESS: at sentence #270000, processed 5984023 words, keeping 76878 word types\n",
      "2022-07-27 22:39:54,295 : INFO : PROGRESS: at sentence #280000, processed 6200528 words, keeping 77999 word types\n",
      "2022-07-27 22:39:54,364 : INFO : PROGRESS: at sentence #290000, processed 6425501 words, keeping 79173 word types\n",
      "2022-07-27 22:39:54,431 : INFO : PROGRESS: at sentence #300000, processed 6644277 words, keeping 80295 word types\n",
      "2022-07-27 22:39:54,508 : INFO : PROGRESS: at sentence #310000, processed 6868240 words, keeping 81366 word types\n",
      "2022-07-27 22:39:54,571 : INFO : PROGRESS: at sentence #320000, processed 7087467 words, keeping 82460 word types\n",
      "2022-07-27 22:39:54,636 : INFO : PROGRESS: at sentence #330000, processed 7309536 words, keeping 83564 word types\n",
      "2022-07-27 22:39:54,687 : INFO : PROGRESS: at sentence #340000, processed 7528477 words, keeping 84489 word types\n",
      "2022-07-27 22:39:54,739 : INFO : PROGRESS: at sentence #350000, processed 7746828 words, keeping 85609 word types\n",
      "2022-07-27 22:39:54,793 : INFO : PROGRESS: at sentence #360000, processed 7969068 words, keeping 86593 word types\n",
      "2022-07-27 22:39:54,844 : INFO : PROGRESS: at sentence #370000, processed 8188129 words, keeping 87544 word types\n",
      "2022-07-27 22:39:54,893 : INFO : PROGRESS: at sentence #380000, processed 8407855 words, keeping 88584 word types\n",
      "2022-07-27 22:39:54,945 : INFO : PROGRESS: at sentence #390000, processed 8630228 words, keeping 89558 word types\n",
      "2022-07-27 22:39:54,999 : INFO : PROGRESS: at sentence #400000, processed 8849388 words, keeping 90536 word types\n",
      "2022-07-27 22:39:55,052 : INFO : PROGRESS: at sentence #410000, processed 9068219 words, keeping 91399 word types\n",
      "2022-07-27 22:39:55,102 : INFO : PROGRESS: at sentence #420000, processed 9289343 words, keeping 92285 word types\n",
      "2022-07-27 22:39:55,149 : INFO : PROGRESS: at sentence #430000, processed 9507740 words, keeping 93227 word types\n",
      "2022-07-27 22:39:55,211 : INFO : PROGRESS: at sentence #440000, processed 9733259 words, keeping 94206 word types\n",
      "2022-07-27 22:39:55,255 : INFO : PROGRESS: at sentence #450000, processed 9951946 words, keeping 95040 word types\n",
      "2022-07-27 22:39:55,304 : INFO : PROGRESS: at sentence #460000, processed 10175779 words, keeping 95839 word types\n",
      "2022-07-27 22:39:55,355 : INFO : PROGRESS: at sentence #470000, processed 10396243 words, keeping 96704 word types\n",
      "2022-07-27 22:39:55,399 : INFO : PROGRESS: at sentence #480000, processed 10615242 words, keeping 97534 word types\n",
      "2022-07-27 22:39:55,447 : INFO : PROGRESS: at sentence #490000, processed 10832426 words, keeping 98357 word types\n",
      "2022-07-27 22:39:55,489 : INFO : PROGRESS: at sentence #500000, processed 11048267 words, keeping 99122 word types\n",
      "2022-07-27 22:39:55,540 : INFO : PROGRESS: at sentence #510000, processed 11270782 words, keeping 100017 word types\n",
      "2022-07-27 22:39:55,598 : INFO : PROGRESS: at sentence #520000, processed 11498711 words, keeping 100881 word types\n",
      "2022-07-27 22:39:55,652 : INFO : PROGRESS: at sentence #530000, processed 11722012 words, keeping 101692 word types\n",
      "2022-07-27 22:39:55,688 : INFO : collected 102305 word types from a corpus of 11877527 raw words and 537055 sentences\n",
      "2022-07-27 22:39:55,689 : INFO : Creating a fresh vocabulary\n",
      "2022-07-27 22:39:55,785 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=40 retains 13056 unique words (12.761839597282636%% of original 102305, drops 89249)', 'datetime': '2022-07-27T22:39:55.785701', 'gensim': '4.1.2', 'python': '3.7.5 (tags/v3.7.5:5c02a39a0b, Oct 15 2019, 00:11:34) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2022-07-27 22:39:55,787 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=40 leaves 11401023 word corpus (95.98818845033988%% of original 11877527, drops 476504)', 'datetime': '2022-07-27T22:39:55.786698', 'gensim': '4.1.2', 'python': '3.7.5 (tags/v3.7.5:5c02a39a0b, Oct 15 2019, 00:11:34) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2022-07-27 22:39:55,868 : INFO : deleting the raw counts dictionary of 102305 items\n",
      "2022-07-27 22:39:55,871 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2022-07-27 22:39:55,872 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 8394666.956889741 word corpus (73.6%% of prior 11401023)', 'datetime': '2022-07-27T22:39:55.872263', 'gensim': '4.1.2', 'python': '3.7.5 (tags/v3.7.5:5c02a39a0b, Oct 15 2019, 00:11:34) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2022-07-27 22:39:56,014 : INFO : estimated required memory for 13056 words and 300 dimensions: 37862400 bytes\n",
      "2022-07-27 22:39:56,015 : INFO : resetting layer weights\n",
      "2022-07-27 22:39:56,164 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-07-27T22:39:56.164908', 'gensim': '4.1.2', 'python': '3.7.5 (tags/v3.7.5:5c02a39a0b, Oct 15 2019, 00:11:34) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2022-07-27 22:39:56,165 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 13056 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2022-07-27T22:39:56.165180', 'gensim': '4.1.2', 'python': '3.7.5 (tags/v3.7.5:5c02a39a0b, Oct 15 2019, 00:11:34) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2022-07-27 22:39:57,180 : INFO : EPOCH 1 - PROGRESS: at 8.29% examples, 696051 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:39:58,200 : INFO : EPOCH 1 - PROGRESS: at 17.29% examples, 717960 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 22:39:59,213 : INFO : EPOCH 1 - PROGRESS: at 24.70% examples, 685250 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:00,218 : INFO : EPOCH 1 - PROGRESS: at 33.82% examples, 703267 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:01,219 : INFO : EPOCH 1 - PROGRESS: at 43.42% examples, 724499 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:02,219 : INFO : EPOCH 1 - PROGRESS: at 52.98% examples, 736441 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:03,225 : INFO : EPOCH 1 - PROGRESS: at 62.11% examples, 740591 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:04,234 : INFO : EPOCH 1 - PROGRESS: at 71.32% examples, 743252 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:05,237 : INFO : EPOCH 1 - PROGRESS: at 80.02% examples, 741213 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:06,252 : INFO : EPOCH 1 - PROGRESS: at 89.33% examples, 744315 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:07,259 : INFO : EPOCH 1 - PROGRESS: at 98.91% examples, 749208 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:07,346 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-07-27 22:40:07,348 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-07-27 22:40:07,357 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-07-27 22:40:07,361 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-07-27 22:40:07,362 : INFO : EPOCH - 1 : training on 11877527 raw words (8394369 effective words) took 11.2s, 750486 effective words/s\n",
      "2022-07-27 22:40:08,375 : INFO : EPOCH 2 - PROGRESS: at 9.48% examples, 793490 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:09,380 : INFO : EPOCH 2 - PROGRESS: at 19.29% examples, 807007 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:10,388 : INFO : EPOCH 2 - PROGRESS: at 28.98% examples, 806255 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:11,396 : INFO : EPOCH 2 - PROGRESS: at 38.52% examples, 805984 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:12,398 : INFO : EPOCH 2 - PROGRESS: at 48.14% examples, 805343 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:13,404 : INFO : EPOCH 2 - PROGRESS: at 57.55% examples, 802014 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:14,410 : INFO : EPOCH 2 - PROGRESS: at 65.24% examples, 778622 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:15,414 : INFO : EPOCH 2 - PROGRESS: at 74.43% examples, 777068 words/s, in_qsize 8, out_qsize 0\n",
      "2022-07-27 22:40:16,418 : INFO : EPOCH 2 - PROGRESS: at 84.04% examples, 779731 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:17,425 : INFO : EPOCH 2 - PROGRESS: at 93.55% examples, 780265 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:18,092 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-07-27 22:40:18,102 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-07-27 22:40:18,104 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-07-27 22:40:18,123 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-07-27 22:40:18,124 : INFO : EPOCH - 2 : training on 11877527 raw words (8396087 effective words) took 10.8s, 780765 effective words/s\n",
      "2022-07-27 22:40:19,134 : INFO : EPOCH 3 - PROGRESS: at 8.91% examples, 746026 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:20,135 : INFO : EPOCH 3 - PROGRESS: at 18.04% examples, 756759 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:21,138 : INFO : EPOCH 3 - PROGRESS: at 27.09% examples, 757901 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:22,139 : INFO : EPOCH 3 - PROGRESS: at 36.44% examples, 765341 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:23,143 : INFO : EPOCH 3 - PROGRESS: at 45.95% examples, 770993 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:24,149 : INFO : EPOCH 3 - PROGRESS: at 55.14% examples, 770013 words/s, in_qsize 8, out_qsize 0\n",
      "2022-07-27 22:40:25,159 : INFO : EPOCH 3 - PROGRESS: at 64.50% examples, 770836 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:26,164 : INFO : EPOCH 3 - PROGRESS: at 72.90% examples, 762182 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:27,168 : INFO : EPOCH 3 - PROGRESS: at 81.43% examples, 756466 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:28,189 : INFO : EPOCH 3 - PROGRESS: at 89.50% examples, 746966 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:29,197 : INFO : EPOCH 3 - PROGRESS: at 96.99% examples, 735663 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:29,541 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-07-27 22:40:29,554 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-07-27 22:40:29,559 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-07-27 22:40:29,573 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-07-27 22:40:29,575 : INFO : EPOCH - 3 : training on 11877527 raw words (8394227 effective words) took 11.4s, 733539 effective words/s\n",
      "2022-07-27 22:40:30,596 : INFO : EPOCH 4 - PROGRESS: at 8.04% examples, 669555 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:31,601 : INFO : EPOCH 4 - PROGRESS: at 16.96% examples, 706742 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:32,610 : INFO : EPOCH 4 - PROGRESS: at 25.72% examples, 715629 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:33,631 : INFO : EPOCH 4 - PROGRESS: at 35.14% examples, 729955 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:34,633 : INFO : EPOCH 4 - PROGRESS: at 44.45% examples, 740231 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:35,639 : INFO : EPOCH 4 - PROGRESS: at 52.80% examples, 732693 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:36,655 : INFO : EPOCH 4 - PROGRESS: at 61.33% examples, 729161 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:37,664 : INFO : EPOCH 4 - PROGRESS: at 69.89% examples, 726196 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:38,675 : INFO : EPOCH 4 - PROGRESS: at 78.40% examples, 724002 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:39,680 : INFO : EPOCH 4 - PROGRESS: at 86.13% examples, 716226 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:40,684 : INFO : EPOCH 4 - PROGRESS: at 93.95% examples, 709865 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:41,435 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-07-27 22:40:41,442 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-07-27 22:40:41,446 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-07-27 22:40:41,459 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-07-27 22:40:41,460 : INFO : EPOCH - 4 : training on 11877527 raw words (8394870 effective words) took 11.9s, 706830 effective words/s\n",
      "2022-07-27 22:40:42,474 : INFO : EPOCH 5 - PROGRESS: at 7.78% examples, 655691 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:43,475 : INFO : EPOCH 5 - PROGRESS: at 16.80% examples, 705136 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:44,477 : INFO : EPOCH 5 - PROGRESS: at 25.47% examples, 713886 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:45,493 : INFO : EPOCH 5 - PROGRESS: at 34.31% examples, 717634 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:46,499 : INFO : EPOCH 5 - PROGRESS: at 43.32% examples, 725553 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:47,510 : INFO : EPOCH 5 - PROGRESS: at 52.04% examples, 724392 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:48,517 : INFO : EPOCH 5 - PROGRESS: at 59.99% examples, 715973 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:49,519 : INFO : EPOCH 5 - PROGRESS: at 68.86% examples, 718995 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:50,526 : INFO : EPOCH 5 - PROGRESS: at 77.80% examples, 721560 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:51,537 : INFO : EPOCH 5 - PROGRESS: at 86.13% examples, 718427 words/s, in_qsize 8, out_qsize 0\n",
      "2022-07-27 22:40:52,554 : INFO : EPOCH 5 - PROGRESS: at 93.37% examples, 706677 words/s, in_qsize 7, out_qsize 0\n",
      "2022-07-27 22:40:53,458 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-07-27 22:40:53,477 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-07-27 22:40:53,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-07-27 22:40:53,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 22:40:53,488 : INFO : EPOCH - 5 : training on 11877527 raw words (8395454 effective words) took 12.0s, 698648 effective words/s\n",
      "2022-07-27 22:40:53,489 : INFO : Word2Vec lifecycle event {'msg': 'training on 59387635 raw words (41975007 effective words) took 57.3s, 732240 effective words/s', 'datetime': '2022-07-27T22:40:53.489684', 'gensim': '4.1.2', 'python': '3.7.5 (tags/v3.7.5:5c02a39a0b, Oct 15 2019, 00:11:34) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2022-07-27 22:40:53,490 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=13056, vector_size=300, alpha=0.025)', 'datetime': '2022-07-27T22:40:53.490680', 'gensim': '4.1.2', 'python': '3.7.5 (tags/v3.7.5:5c02a39a0b, Oct 15 2019, 00:11:34) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "h:\\python\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  if __name__ == '__main__':\n",
      "2022-07-27 22:40:53,512 : WARNING : destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
      "2022-07-27 22:40:53,515 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'G:\\\\大三下\\\\summer_workshop\\\\NLP\\\\项目实战-英文电影评论情感分析\\\\models\\\\300features_40minwords_10context.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-07-27T22:40:53.515613', 'gensim': '4.1.2', 'python': '3.7.5 (tags/v3.7.5:5c02a39a0b, Oct 15 2019, 00:11:34) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2022-07-27 22:40:53,516 : INFO : not storing attribute cum_table\n",
      "2022-07-27 22:40:53,992 : INFO : saved G:\\大三下\\summer_workshop\\NLP\\项目实战-英文电影评论情感分析\\models\\300features_40minwords_10context.model\n"
     ]
    }
   ],
   "source": [
    "print('Training model...')\n",
    "#word2vec.\n",
    "model = Word2Vec(sentences, workers=num_workers, \\\n",
    "            vector_size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model.save(os.path.join('.', 'models', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.6219446659088135),\n",
       " ('lady', 0.5837732553482056),\n",
       " ('lad', 0.578706681728363),\n",
       " ('person', 0.5187705755233765),\n",
       " ('chap', 0.5139498114585876),\n",
       " ('men', 0.5075100660324097),\n",
       " ('guy', 0.5022870302200317),\n",
       " ('millionaire', 0.49241602420806885),\n",
       " ('soldier', 0.4914490580558777),\n",
       " ('boy', 0.49031269550323486)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text, remove_stopwords=False):\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    words = text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        words = [w for w in words if w not in eng_stopwords]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 22:44:13,299 : INFO : loading Word2Vec object from G:\\大三下\\summer_workshop\\NLP\\项目实战-英文电影评论情感分析\\models\\300features_40minwords_10context.model\n",
      "2022-07-27 22:44:13,343 : INFO : loading wv recursively from G:\\大三下\\summer_workshop\\NLP\\项目实战-英文电影评论情感分析\\models\\300features_40minwords_10context.model.wv.* with mmap=None\n",
      "2022-07-27 22:44:13,343 : INFO : setting ignored attribute cum_table to None\n",
      "2022-07-27 22:44:13,459 : INFO : Word2Vec lifecycle event {'fname': 'G:\\\\大三下\\\\summer_workshop\\\\NLP\\\\项目实战-英文电影评论情感分析\\\\models\\\\300features_40minwords_10context.model', 'datetime': '2022-07-27T22:44:13.459103', 'gensim': '4.1.2', 'python': '3.7.5 (tags/v3.7.5:5c02a39a0b, Oct 15 2019, 00:11:34) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "model_name = '300features_40minwords_10context.model'\n",
    "model = Word2Vec.load(os.path.join('.', 'models', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 25000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\"The Classic War of the Worlds\" by Timothy Hin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \"The Classic War of the Worlds\" by Timothy Hin...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_dataset('labeled_train')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_review_vector(review):\n",
    "    words = clean_text(review, remove_stopwords=True)\n",
    "    array = np.array([model.wv[w] for w in words if w in model.wv])\n",
    "    return pd.Series(array.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>-0.009208</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>-0.013443</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.012015</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.011367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002624</td>\n",
       "      <td>-0.004158</td>\n",
       "      <td>-0.004192</td>\n",
       "      <td>0.025917</td>\n",
       "      <td>-0.021137</td>\n",
       "      <td>-0.019853</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>-0.010292</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008158</td>\n",
       "      <td>0.027282</td>\n",
       "      <td>0.011276</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.042252</td>\n",
       "      <td>-0.008082</td>\n",
       "      <td>0.015025</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>0.032473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.017988</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>0.023650</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>-0.008607</td>\n",
       "      <td>-0.016504</td>\n",
       "      <td>0.025702</td>\n",
       "      <td>0.032836</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>-0.001806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020052</td>\n",
       "      <td>0.029908</td>\n",
       "      <td>0.016645</td>\n",
       "      <td>-0.001345</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.019387</td>\n",
       "      <td>0.014137</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>-0.008471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>0.010928</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>-0.005427</td>\n",
       "      <td>-0.025233</td>\n",
       "      <td>0.038303</td>\n",
       "      <td>0.015241</td>\n",
       "      <td>0.027771</td>\n",
       "      <td>0.010512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>0.034523</td>\n",
       "      <td>0.010521</td>\n",
       "      <td>0.020109</td>\n",
       "      <td>0.025032</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.013321</td>\n",
       "      <td>0.024813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.007396</td>\n",
       "      <td>0.009958</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>-0.014578</td>\n",
       "      <td>0.028299</td>\n",
       "      <td>0.025850</td>\n",
       "      <td>0.008054</td>\n",
       "      <td>0.011531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011889</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>-0.005417</td>\n",
       "      <td>-0.000587</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>-0.002423</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.003298  0.003135 -0.000681  0.002669  0.002552 -0.009208  0.013695   \n",
       "1 -0.002624 -0.004158 -0.004192  0.025917 -0.021137 -0.019853  0.003270   \n",
       "2 -0.017988  0.006175  0.023650  0.004711 -0.008607 -0.016504  0.025702   \n",
       "3  0.000232  0.009102  0.010928  0.016225 -0.005427 -0.025233  0.038303   \n",
       "4 -0.007396  0.009958  0.024086  0.014096  0.003327 -0.014578  0.028299   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0 -0.013443  0.014523  0.010945  ... -0.004829  0.003228 -0.000676  0.008296   \n",
       "1 -0.010292  0.005942  0.001697  ...  0.008158  0.027282  0.011276  0.002243   \n",
       "2  0.032836  0.007475 -0.001806  ...  0.020052  0.029908  0.016645 -0.001345   \n",
       "3  0.015241  0.027771  0.010512  ... -0.009901  0.034523  0.010521  0.020109   \n",
       "4  0.025850  0.008054  0.011531  ... -0.011889  0.010741 -0.005417 -0.000587   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.010555  0.003252  0.012015  0.002042  0.008913  0.011367  \n",
       "1  0.042252 -0.008082  0.015025  0.003151  0.008413  0.032473  \n",
       "2  0.029081  0.019387  0.014137  0.001464  0.015711 -0.008471  \n",
       "3  0.025032  0.002334  0.011945 -0.000044  0.013321  0.024813  \n",
       "4  0.012703  0.005625 -0.002423  0.002269  0.007645  0.000817  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features = df.review.apply(to_review_vector)\n",
    "train_data_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Columns: 300 entries, 0 to 299\n",
      "dtypes: float32(300)\n",
      "memory usage: 28.6 MB\n"
     ]
    }
   ],
   "source": [
    "train_data_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "forest = forest.fit(train_data_features, df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12500,     0],\n",
       "       [    0, 12500]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df.sentiment, forest.predict(train_data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positive': 6,\n",
       " 'Negative': 2,\n",
       " 'Polarity': 0.4999999375000079,\n",
       " 'Subjectivity': 0.055172413412604045}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pysentiment as ps\n",
    "#initalize lm\n",
    "lm = ps.LM()\n",
    "#Text to be analyzed\n",
    "test_text = \"Cisco Posts Another Record Quarter With Growth Across All Segments; Raising FVE to $46Cisco's first-quarter results modestly beat our top line and net income expectations while the $0.77 earnings per share exceeded our expected result due to an increased quantity of shares repurchased. The narrow-moat firm posted 8% year-over-year revenue growth, with strength across all the business segments and provided strong guidance for the next quarter. After updating our Cisco forecast to consider stronger growth driven by expected cross selling of multi-cloud environment products, security solutions, and infrastructure hardware, we are raising our fair value estimate to $46 per share from $43. With shares trading around our fair value estimate after hours, we recommend for investors to sustain their Cisco positions.The company guided the second quarter to have a 5%-7% growth over the previous year with 30.5%-31.5% non-GAAP operating margins. Cisco is benefitting from a strong IT spending environment, and we believe that the company's product roadmap has made the it a one-stop-shop for networking environments. Two major recent announcements by Cisco were its integration of security into SD-WAN products and its offering of production grade Kubernetes to be run on premises and then offloaded to Amazon AWS. We like that Cisco is intertwining previously siloed offerings into combined solutions that contain unique selling features. Additionally, having support with all three major hyperscale public cloud providers allows Cisco to be a commonality for IT teams balancing on-premises, private, and public cloud environments. We like that Cisco has completely embraced the cloud as a path to growth instead of a business threat. In our view, Cisco's innovative product portfolio should keep it on the shortlist for enterprise customers debating networking infrastructure providers for hardware, software, and services in cloud environments or on premises.\"\t\n",
    "#split words and get tokens\t\n",
    "words = lm.tokenize(test_text)\t\n",
    "#get score\t\n",
    "score = lm.get_score(words)\t\n",
    "#score\t\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emo_analysis(word='good'):\n",
    "    lm = ps.LM()\n",
    "    words = lm.tokenize(word)\n",
    "    score = lm.get_score(words)\n",
    "    if score['Positive'] > score['Negative']:\n",
    "        emo = 1\n",
    "    elif score['Positive'] < score['Negative']:\n",
    "        emo = -1\n",
    "    else:\n",
    "        try:\n",
    "            text = pd.DataFrame(columns=['id','review'])\n",
    "            text.loc[0,:]=[1,word]\n",
    "            features = text.review.apply(to_review_vector)\n",
    "            result = forest.predict(features)\n",
    "            if result[0] ==1:\n",
    "                emo = 1\n",
    "            else:\n",
    "                emo = -1\n",
    "        except:\n",
    "            emo = 0\n",
    "    return emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emo_analysis('Dow Jones Futures: Apple Leads Earnings Wave, Fed Rate Hike Looms; What To Do Now')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
